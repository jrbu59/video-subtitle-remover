#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éªŒè¯å­—å¹•å»é™¤æ•ˆæœçš„è„šæœ¬
ä½¿ç”¨Geminiåˆ†æåŸè§†é¢‘å’Œå¤„ç†åè§†é¢‘ï¼Œå¯¹æ¯”å­—å¹•å»é™¤æ•ˆæœ
"""

import os
import sys
import logging
import cv2
import numpy as np
from pathlib import Path

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
from backend.api.models.timed_subtitle import TimedSubtitleRegion, TimedSubtitleAnalysis
from backend.api.gemini.token_manager import TokenManager
from backend.api.gemini.gemini_timed_client import GeminiTimedClient
from backend.api.gemini.gemini_client import GeminiClient, SubtitleAnalysis, SubtitleRegion
from backend import config


def analyze_video_with_gemini(video_path: str, client_type="simple") -> dict:
    """
    ä½¿ç”¨Geminiåˆ†æè§†é¢‘ä¸­çš„å­—å¹•

    Args:
        video_path: è§†é¢‘è·¯å¾„
        client_type: å®¢æˆ·ç«¯ç±»å‹ ("simple" æˆ– "timed")
    """
    try:
        logger.info(f"ä½¿ç”¨Geminiåˆ†æè§†é¢‘: {video_path}")

        # åˆå§‹åŒ–tokenç®¡ç†å™¨
        token_endpoint = "http://api-ladder.ymt.io:8088/rpc/vertexai/accesstoken"
        token_manager = TokenManager(token_endpoint)

        if client_type == "timed":
            # ä½¿ç”¨æ—¶é—´æ®µå®¢æˆ·ç«¯
            gemini_client = GeminiTimedClient(token_manager)
            analysis = gemini_client.analyze_subtitle_with_time(video_path, sample_frames=15)

            if analysis:
                return {
                    "success": True,
                    "has_subtitles": analysis.has_subtitles,
                    "subtitle_type": analysis.subtitle_type,
                    "regions_count": len(analysis.timed_regions),
                    "total_frames": analysis.total_frames,
                    "fps": analysis.fps,
                    "regions": [
                        {
                            "start_frame": r.start_frame,
                            "end_frame": r.end_frame,
                            "x": r.x, "y": r.y, "width": r.width, "height": r.height,
                            "confidence": r.confidence,
                            "text": r.text_content
                        } for r in analysis.timed_regions
                    ]
                }
        else:
            # ä½¿ç”¨ç®€å•å®¢æˆ·ç«¯
            gemini_client = GeminiClient(token_manager)
            analysis = gemini_client.analyze_subtitle_with_gemini(video_path, sample_frames=8)

            if analysis:
                return {
                    "success": True,
                    "has_subtitles": analysis.has_subtitles,
                    "subtitle_type": analysis.subtitle_type,
                    "regions_count": len(analysis.regions),
                    "regions": [
                        {
                            "x": r.x, "y": r.y, "width": r.width, "height": r.height,
                            "confidence": r.confidence,
                            "text": r.text_content
                        } for r in analysis.regions
                    ]
                }

        return {"success": False, "error": "Gemini APIè¿”å›ç©ºç»“æœ"}

    except Exception as e:
        logger.error(f"Geminiåˆ†æå¼‚å¸¸: {e}")
        return {"success": False, "error": str(e)}


def create_mock_analysis_for_debugging(video_path: str) -> dict:
    """
    åˆ›å»ºè°ƒè¯•ç”¨çš„æ¨¡æ‹Ÿåˆ†æç»“æœ
    """
    # è·å–è§†é¢‘ä¿¡æ¯
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        return {"success": False, "error": "æ— æ³•æ‰“å¼€è§†é¢‘"}

    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    cap.release()

    logger.info(f"è§†é¢‘ä¿¡æ¯: {width}x{height}, {total_frames}å¸§, {fps}fps")

    return {
        "success": True,
        "has_subtitles": True,
        "subtitle_type": "hard",
        "regions_count": 1,
        "regions": [
            {
                "x": int(width * 0.1),
                "y": int(height * 0.85),
                "width": int(width * 0.8),
                "height": int(height * 0.1),
                "confidence": 0.9,
                "text": "Mock subtitle region for debugging"
            }
        ]
    }


def extract_frames_for_comparison(video_path: str, frame_numbers: list) -> dict:
    """
    ä»è§†é¢‘ä¸­æå–æŒ‡å®šå¸§ç”¨äºå¯¹æ¯”

    Args:
        video_path: è§†é¢‘è·¯å¾„
        frame_numbers: è¦æå–çš„å¸§å·åˆ—è¡¨
    """
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        return {}

    frames = {}
    for frame_no in frame_numbers:
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_no)
        ret, frame = cap.read()
        if ret:
            frames[frame_no] = frame

    cap.release()
    return frames


def save_comparison_frames(original_frames: dict, processed_frames: dict, output_dir: str):
    """
    ä¿å­˜å¯¹æ¯”å¸§åˆ°æ–‡ä»¶
    """
    os.makedirs(output_dir, exist_ok=True)

    for frame_no in original_frames.keys():
        if frame_no in processed_frames:
            # ä¿å­˜åŸå§‹å¸§
            orig_path = os.path.join(output_dir, f"frame_{frame_no:04d}_original.jpg")
            cv2.imwrite(orig_path, original_frames[frame_no])

            # ä¿å­˜å¤„ç†åå¸§
            proc_path = os.path.join(output_dir, f"frame_{frame_no:04d}_processed.jpg")
            cv2.imwrite(proc_path, processed_frames[frame_no])

            # åˆ›å»ºå¯¹æ¯”å›¾
            orig = original_frames[frame_no]
            proc = processed_frames[frame_no]

            # è®¡ç®—å·®å¼‚
            diff = cv2.absdiff(orig, proc)

            # å¹¶æ’æ˜¾ç¤º
            comparison = np.hstack([orig, proc, diff])
            comp_path = os.path.join(output_dir, f"frame_{frame_no:04d}_comparison.jpg")
            cv2.imwrite(comp_path, comparison)

            logger.info(f"ä¿å­˜å¯¹æ¯”å¸§: {comp_path}")


def main():
    """ä¸»å‡½æ•°"""
    # è§†é¢‘è·¯å¾„
    original_video = "/home/jiarui/software/video-subtitle-remover/videos/test_video_with_subtitle.mp4"
    processed_video = "/home/jiarui/software/video-subtitle-remover/videos/test_video_with_subtitle_no_subtitle_timed.mp4"

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(original_video):
        logger.error(f"åŸå§‹è§†é¢‘ä¸å­˜åœ¨: {original_video}")
        return

    if not os.path.exists(processed_video):
        logger.error(f"å¤„ç†åè§†é¢‘ä¸å­˜åœ¨: {processed_video}")
        return

    print(f"\n{'='*80}")
    print("å­—å¹•å»é™¤æ•ˆæœéªŒè¯")
    print(f"{'='*80}")
    print(f"åŸå§‹è§†é¢‘: {original_video}")
    print(f"å¤„ç†åè§†é¢‘: {processed_video}")
    print(f"{'='*80}\n")

    # åˆ†æåŸå§‹è§†é¢‘
    logger.info("1. åˆ†æåŸå§‹è§†é¢‘...")
    use_real_gemini = True  # è®¾ç½®ä¸ºTrueä½¿ç”¨çœŸå®Gemini APIï¼ŒFalseä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®

    if use_real_gemini:
        original_analysis = analyze_video_with_gemini(original_video, "simple")
    else:
        logger.info("ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œåˆ†æ")
        original_analysis = create_mock_analysis_for_debugging(original_video)

    print("åŸå§‹è§†é¢‘åˆ†æç»“æœ:")
    print(f"  æˆåŠŸ: {original_analysis.get('success', False)}")
    if original_analysis.get('success'):
        print(f"  åŒ…å«å­—å¹•: {original_analysis.get('has_subtitles', False)}")
        print(f"  å­—å¹•åŒºåŸŸæ•°: {original_analysis.get('regions_count', 0)}")
        for i, region in enumerate(original_analysis.get('regions', [])):
            print(f"    åŒºåŸŸ{i+1}: ({region['x']}, {region['y']}) {region['width']}x{region['height']} ç½®ä¿¡åº¦:{region['confidence']:.2f}")
    else:
        print(f"  é”™è¯¯: {original_analysis.get('error', 'æœªçŸ¥é”™è¯¯')}")

    # åˆ†æå¤„ç†åè§†é¢‘
    logger.info("2. åˆ†æå¤„ç†åè§†é¢‘...")
    if use_real_gemini:
        processed_analysis = analyze_video_with_gemini(processed_video, "simple")
    else:
        processed_analysis = create_mock_analysis_for_debugging(processed_video)

    print("\nå¤„ç†åè§†é¢‘åˆ†æç»“æœ:")
    print(f"  æˆåŠŸ: {processed_analysis.get('success', False)}")
    if processed_analysis.get('success'):
        print(f"  åŒ…å«å­—å¹•: {processed_analysis.get('has_subtitles', False)}")
        print(f"  å­—å¹•åŒºåŸŸæ•°: {processed_analysis.get('regions_count', 0)}")
        for i, region in enumerate(processed_analysis.get('regions', [])):
            print(f"    åŒºåŸŸ{i+1}: ({region['x']}, {region['y']}) {region['width']}x{region['height']} ç½®ä¿¡åº¦:{region['confidence']:.2f}")
    else:
        print(f"  é”™è¯¯: {processed_analysis.get('error', 'æœªçŸ¥é”™è¯¯')}")

    # å¯¹æ¯”ç»“æœ
    print(f"\n{'='*80}")
    print("å¯¹æ¯”åˆ†æ")
    print(f"{'='*80}")

    if original_analysis.get('success') and processed_analysis.get('success'):
        orig_has_subs = original_analysis.get('has_subtitles', False)
        proc_has_subs = processed_analysis.get('has_subtitles', False)

        if orig_has_subs and not proc_has_subs:
            print("âœ… å­—å¹•å»é™¤æˆåŠŸï¼åŸè§†é¢‘æœ‰å­—å¹•ï¼Œå¤„ç†åè§†é¢‘æ— å­—å¹•")
        elif orig_has_subs and proc_has_subs:
            orig_count = original_analysis.get('regions_count', 0)
            proc_count = processed_analysis.get('regions_count', 0)

            if proc_count < orig_count:
                print(f"âš ï¸  éƒ¨åˆ†å­—å¹•å»é™¤ï¼šåŸè§†é¢‘{orig_count}ä¸ªåŒºåŸŸï¼Œå¤„ç†å{proc_count}ä¸ªåŒºåŸŸ")
            else:
                print("âŒ å­—å¹•å»é™¤å¤±è´¥ï¼å¤„ç†åè§†é¢‘ä»æœ‰ç›¸åŒæ•°é‡çš„å­—å¹•åŒºåŸŸ")
        elif not orig_has_subs and not proc_has_subs:
            print("â„¹ï¸  ä¸¤ä¸ªè§†é¢‘éƒ½æ²¡æœ‰æ£€æµ‹åˆ°å­—å¹•")
        else:
            print("ğŸ¤” å¼‚å¸¸æƒ…å†µï¼šåŸè§†é¢‘æ— å­—å¹•ä½†å¤„ç†åæœ‰å­—å¹•")

    # æå–å…³é”®å¸§è¿›è¡Œè§†è§‰å¯¹æ¯”
    logger.info("3. æå–å…³é”®å¸§è¿›è¡Œè§†è§‰å¯¹æ¯”...")
    key_frames = [10, 50, 100, 150, 200, 250]  # æå–ä¸€äº›å…³é”®å¸§

    original_frames = extract_frames_for_comparison(original_video, key_frames)
    processed_frames = extract_frames_for_comparison(processed_video, key_frames)

    if original_frames and processed_frames:
        comparison_dir = "frame_comparisons"
        save_comparison_frames(original_frames, processed_frames, comparison_dir)
        print(f"\nğŸ“¸ å…³é”®å¸§å¯¹æ¯”å›¾å·²ä¿å­˜åˆ°: {comparison_dir}/")
        print("    å¯ä»¥æŸ¥çœ‹ *_comparison.jpg æ–‡ä»¶æ¥ç›´è§‚å¯¹æ¯”æ•ˆæœ")

    # ç»™å‡ºè°ƒè¯•å»ºè®®
    print(f"\n{'='*80}")
    print("è°ƒè¯•å»ºè®®")
    print(f"{'='*80}")

    if not use_real_gemini:
        print("1. å½“å‰ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ï¼Œå»ºè®®å¯ç”¨çœŸå®Gemini APIéªŒè¯")
        print("   å°†è„šæœ¬ä¸­ use_real_gemini è®¾ç½®ä¸º True")

    print("2. æ£€æŸ¥å­—å¹•åŒºåŸŸåæ ‡æ˜¯å¦æ­£ç¡®:")
    if original_analysis.get('success') and original_analysis.get('regions'):
        region = original_analysis['regions'][0]
        print(f"   æ£€æµ‹åˆ°çš„åŒºåŸŸ: x={region['x']}, y={region['y']}, w={region['width']}, h={region['height']}")
        print("   ç¡®è®¤è¿™ä¸ªåŒºåŸŸæ˜¯å¦è¦†ç›–äº†å®é™…çš„å­—å¹•ä½ç½®")

    print("3. æ£€æŸ¥æ—¶é—´æ®µè®¾ç½®:")
    print("   ç¡®è®¤æ¨¡æ‹Ÿçš„æ—¶é—´æ®µ(0-4s, 6-9s)æ˜¯å¦ä¸å®é™…å­—å¹•å‡ºç°æ—¶é—´ä¸€è‡´")

    print("4. æŸ¥çœ‹frame_comparisonsç›®å½•ä¸­çš„å¯¹æ¯”å›¾:")
    print("   - *_original.jpg: åŸå§‹å¸§")
    print("   - *_processed.jpg: å¤„ç†åå¸§")
    print("   - *_comparison.jpg: å¹¶æ’å¯¹æ¯”å›¾")


if __name__ == "__main__":
    main()